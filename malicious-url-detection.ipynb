{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:54:37.791055Z",
     "iopub.status.busy": "2025-04-25T12:54:37.790299Z",
     "iopub.status.idle": "2025-04-25T12:54:45.599916Z",
     "shell.execute_reply": "2025-04-25T12:54:45.599205Z",
     "shell.execute_reply.started": "2025-04-25T12:54:37.791016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# extract the domain name from a URL (Extract the top level domain (TLD) from the URL given).\n",
    "\n",
    "!pip install tld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "# üì• Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:54:45.601742Z",
     "iopub.status.busy": "2025-04-25T12:54:45.601490Z",
     "iopub.status.idle": "2025-04-25T12:54:46.715414Z",
     "shell.execute_reply": "2025-04-25T12:54:46.714896Z",
     "shell.execute_reply.started": "2025-04-25T12:54:45.601712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "from colorama import Fore  #Colorama is a module to color the python outputs\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "# This module defines a standard interface to break Uniform Resource Locator (URL) \n",
    "# strings up in components (addressing scheme, network location, path etc.), \n",
    "# to combine the components back into a URL string, \n",
    "# and to convert a ‚Äúrelative URL‚Äù to an absolute URL given a ‚Äúbase URL.‚Äù\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from tld import get_tld, is_tld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "# üóÉÔ∏è Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:54:46.716514Z",
     "iopub.status.busy": "2025-04-25T12:54:46.716319Z",
     "iopub.status.idle": "2025-04-25T12:54:47.991427Z",
     "shell.execute_reply": "2025-04-25T12:54:47.990756Z",
     "shell.execute_reply.started": "2025-04-25T12:54:46.716489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/malicious-urls-dataset/malicious_phish.csv')\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "# üìù Meta information of Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:54:47.993159Z",
     "iopub.status.busy": "2025-04-25T12:54:47.992957Z",
     "iopub.status.idle": "2025-04-25T12:54:48.070203Z",
     "shell.execute_reply": "2025-04-25T12:54:48.069479Z",
     "shell.execute_reply.started": "2025-04-25T12:54:47.993134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "# üîé Checking for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:54:48.071237Z",
     "iopub.status.busy": "2025-04-25T12:54:48.071067Z",
     "iopub.status.idle": "2025-04-25T12:54:48.136713Z",
     "shell.execute_reply": "2025-04-25T12:54:48.136062Z",
     "shell.execute_reply.started": "2025-04-25T12:54:48.071215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:54:50.165211Z",
     "iopub.status.busy": "2025-04-25T12:54:50.164392Z",
     "iopub.status.idle": "2025-04-25T12:54:50.205273Z",
     "shell.execute_reply": "2025-04-25T12:54:50.204603Z",
     "shell.execute_reply.started": "2025-04-25T12:54:50.165171Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "count = data.type.value_counts()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:54:52.440699Z",
     "iopub.status.busy": "2025-04-25T12:54:52.439954Z",
     "iopub.status.idle": "2025-04-25T12:54:52.445537Z",
     "shell.execute_reply": "2025-04-25T12:54:52.444688Z",
     "shell.execute_reply.started": "2025-04-25T12:54:52.440665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x=count.index\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:54:54.910084Z",
     "iopub.status.busy": "2025-04-25T12:54:54.909340Z",
     "iopub.status.idle": "2025-04-25T12:54:55.151780Z",
     "shell.execute_reply": "2025-04-25T12:54:55.151063Z",
     "shell.execute_reply.started": "2025-04-25T12:54:54.910050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=count.index, y=count)\n",
    "plt.xlabel('Types')\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:54:57.625240Z",
     "iopub.status.busy": "2025-04-25T12:54:57.624653Z",
     "iopub.status.idle": "2025-04-25T12:54:58.403147Z",
     "shell.execute_reply": "2025-04-25T12:54:58.402429Z",
     "shell.execute_reply.started": "2025-04-25T12:54:57.625210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['url'] = data['url'].replace('www.', '', regex=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:55:00.670743Z",
     "iopub.status.busy": "2025-04-25T12:55:00.670176Z",
     "iopub.status.idle": "2025-04-25T12:55:00.678708Z",
     "shell.execute_reply": "2025-04-25T12:55:00.678018Z",
     "shell.execute_reply.started": "2025-04-25T12:55:00.670710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:55:03.819978Z",
     "iopub.status.busy": "2025-04-25T12:55:03.819439Z",
     "iopub.status.idle": "2025-04-25T12:55:04.171288Z",
     "shell.execute_reply": "2025-04-25T12:55:04.170536Z",
     "shell.execute_reply.started": "2025-04-25T12:55:03.819943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rem = {\"Category\": {\"benign\": 0, \"defacement\": 1, \"phishing\":2, \"malware\":3}}\n",
    "data['Category'] = data['type']\n",
    "data = data.replace(rem)\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:55:06.655693Z",
     "iopub.status.busy": "2025-04-25T12:55:06.654941Z",
     "iopub.status.idle": "2025-04-25T12:55:06.941908Z",
     "shell.execute_reply": "2025-04-25T12:55:06.941127Z",
     "shell.execute_reply.started": "2025-04-25T12:55:06.655637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['url_len'] = data['url'].apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:55:08.785078Z",
     "iopub.status.busy": "2025-04-25T12:55:08.784351Z",
     "iopub.status.idle": "2025-04-25T12:55:08.793597Z",
     "shell.execute_reply": "2025-04-25T12:55:08.792938Z",
     "shell.execute_reply.started": "2025-04-25T12:55:08.785043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:55:10.700109Z",
     "iopub.status.busy": "2025-04-25T12:55:10.699851Z",
     "iopub.status.idle": "2025-04-25T12:55:10.704711Z",
     "shell.execute_reply": "2025-04-25T12:55:10.703972Z",
     "shell.execute_reply.started": "2025-04-25T12:55:10.700080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_tld(url):\n",
    "    try:\n",
    "#         Extract the top level domain (TLD) from the URL given\n",
    "        res = get_tld(url, as_object = True, fail_silently=False,fix_protocol=True)\n",
    "        pri_domain= res.parsed_url.netloc\n",
    "    except :\n",
    "        pri_domain= None\n",
    "    return pri_domain\n",
    "\n",
    "\n",
    "\n",
    "# netloc : Contains the network location - which includes the domain itself (and subdomain if present), \n",
    "# the port number, along with an optional credentials in form of username:password . Together it may take\n",
    "# form of username:password@domain.com:80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:55:12.995430Z",
     "iopub.status.busy": "2025-04-25T12:55:12.994943Z",
     "iopub.status.idle": "2025-04-25T12:55:21.273170Z",
     "shell.execute_reply": "2025-04-25T12:55:21.272581Z",
     "shell.execute_reply.started": "2025-04-25T12:55:12.995397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['domain'] = data['url'].apply(lambda i: process_tld(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:55:21.274492Z",
     "iopub.status.busy": "2025-04-25T12:55:21.274287Z",
     "iopub.status.idle": "2025-04-25T12:55:21.283848Z",
     "shell.execute_reply": "2025-04-25T12:55:21.283020Z",
     "shell.execute_reply.started": "2025-04-25T12:55:21.274468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:58:11.288250Z",
     "iopub.status.busy": "2025-04-25T12:58:11.287646Z",
     "iopub.status.idle": "2025-04-25T12:58:15.492319Z",
     "shell.execute_reply": "2025-04-25T12:58:15.491669Z",
     "shell.execute_reply.started": "2025-04-25T12:58:11.288210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature = ['@','?','-','=','.','#','%','+','$','!','*',',','//']\n",
    "for a in feature:\n",
    "    data[a] = data['url'].apply(lambda i: i.count(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:58:16.553569Z",
     "iopub.status.busy": "2025-04-25T12:58:16.553024Z",
     "iopub.status.idle": "2025-04-25T12:58:16.566953Z",
     "shell.execute_reply": "2025-04-25T12:58:16.566197Z",
     "shell.execute_reply.started": "2025-04-25T12:58:16.553534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:58:18.818286Z",
     "iopub.status.busy": "2025-04-25T12:58:18.817746Z",
     "iopub.status.idle": "2025-04-25T12:58:18.822321Z",
     "shell.execute_reply": "2025-04-25T12:58:18.821572Z",
     "shell.execute_reply.started": "2025-04-25T12:58:18.818252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def abnormal_url(url):\n",
    "    hostname = urlparse(url).hostname\n",
    "    hostname = str(hostname)\n",
    "    match = re.search(hostname, url)\n",
    "    if match:\n",
    "        # print match.group()\n",
    "        return 1\n",
    "    else:\n",
    "        # print 'No matching pattern found'\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# urlparse():This function parses a URL into six components, returning a 6-tuple. \n",
    "# This corresponds to the general structure of a URL. Each tuple item is a string. \n",
    "# The components are not broken up in smaller parts \n",
    "#(for example, the network location is a single string), and % escapes are not expanded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:58:21.497424Z",
     "iopub.status.busy": "2025-04-25T12:58:21.497166Z",
     "iopub.status.idle": "2025-04-25T12:58:32.433121Z",
     "shell.execute_reply": "2025-04-25T12:58:32.432250Z",
     "shell.execute_reply.started": "2025-04-25T12:58:21.497393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['abnormal_url'] = data['url'].apply(lambda i: abnormal_url(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:58:32.434824Z",
     "iopub.status.busy": "2025-04-25T12:58:32.434562Z",
     "iopub.status.idle": "2025-04-25T12:58:32.453373Z",
     "shell.execute_reply": "2025-04-25T12:58:32.452596Z",
     "shell.execute_reply.started": "2025-04-25T12:58:32.434797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:58:32.454691Z",
     "iopub.status.busy": "2025-04-25T12:58:32.454429Z",
     "iopub.status.idle": "2025-04-25T12:58:32.659213Z",
     "shell.execute_reply": "2025-04-25T12:58:32.658491Z",
     "shell.execute_reply.started": "2025-04-25T12:58:32.454658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='abnormal_url', data=data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:58:58.263800Z",
     "iopub.status.busy": "2025-04-25T12:58:58.263151Z",
     "iopub.status.idle": "2025-04-25T12:58:58.267745Z",
     "shell.execute_reply": "2025-04-25T12:58:58.267004Z",
     "shell.execute_reply.started": "2025-04-25T12:58:58.263764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def httpSecure(url):\n",
    "    htp = urlparse(url).scheme #It supports the following URL schemes: file , ftp , gopher , hdl , \n",
    "                               #http , https ... from urllib.parse\n",
    "    match = str(htp)\n",
    "    if match=='https':\n",
    "        # print match.group()\n",
    "        return 1\n",
    "    else:\n",
    "        # print 'No matching pattern found'\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:58:58.322032Z",
     "iopub.status.busy": "2025-04-25T12:58:58.321488Z",
     "iopub.status.idle": "2025-04-25T12:59:01.668830Z",
     "shell.execute_reply": "2025-04-25T12:59:01.668195Z",
     "shell.execute_reply.started": "2025-04-25T12:58:58.322007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['https'] = data['url'].apply(lambda i: httpSecure(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:01.670143Z",
     "iopub.status.busy": "2025-04-25T12:59:01.669941Z",
     "iopub.status.idle": "2025-04-25T12:59:01.687045Z",
     "shell.execute_reply": "2025-04-25T12:59:01.686381Z",
     "shell.execute_reply.started": "2025-04-25T12:59:01.670117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:02.707488Z",
     "iopub.status.busy": "2025-04-25T12:59:02.707012Z",
     "iopub.status.idle": "2025-04-25T12:59:02.914359Z",
     "shell.execute_reply": "2025-04-25T12:59:02.913764Z",
     "shell.execute_reply.started": "2025-04-25T12:59:02.707454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='https', data=data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Counts the number of digit characters in a URL</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:05.173040Z",
     "iopub.status.busy": "2025-04-25T12:59:05.172787Z",
     "iopub.status.idle": "2025-04-25T12:59:05.177091Z",
     "shell.execute_reply": "2025-04-25T12:59:05.176332Z",
     "shell.execute_reply.started": "2025-04-25T12:59:05.173012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def digit_count(url):\n",
    "    digits = 0\n",
    "    for i in url:\n",
    "        if i.isnumeric():\n",
    "            digits = digits + 1\n",
    "    return digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:07.352310Z",
     "iopub.status.busy": "2025-04-25T12:59:07.352048Z",
     "iopub.status.idle": "2025-04-25T12:59:09.586021Z",
     "shell.execute_reply": "2025-04-25T12:59:09.585438Z",
     "shell.execute_reply.started": "2025-04-25T12:59:07.352279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['digits']= data['url'].apply(lambda i: digit_count(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Counts the number of letter characters in a URL</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:10.782652Z",
     "iopub.status.busy": "2025-04-25T12:59:10.781956Z",
     "iopub.status.idle": "2025-04-25T12:59:10.802201Z",
     "shell.execute_reply": "2025-04-25T12:59:10.801400Z",
     "shell.execute_reply.started": "2025-04-25T12:59:10.782607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:13.627331Z",
     "iopub.status.busy": "2025-04-25T12:59:13.627078Z",
     "iopub.status.idle": "2025-04-25T12:59:13.632042Z",
     "shell.execute_reply": "2025-04-25T12:59:13.631234Z",
     "shell.execute_reply.started": "2025-04-25T12:59:13.627301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def letter_count(url):\n",
    "    letters = 0\n",
    "    for i in url:\n",
    "        if i.isalpha():\n",
    "            letters = letters + 1\n",
    "    return letters\n",
    "\n",
    "# The isalpha() method returns True if all the characters are alphabet letters (a-z). \n",
    "# Example of characters that are not alphabet letters: (space)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:17.913193Z",
     "iopub.status.busy": "2025-04-25T12:59:17.912493Z",
     "iopub.status.idle": "2025-04-25T12:59:20.766121Z",
     "shell.execute_reply": "2025-04-25T12:59:20.765450Z",
     "shell.execute_reply.started": "2025-04-25T12:59:17.913157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['letters']= data['url'].apply(lambda i: letter_count(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Checks to see whether URL contains a shortening service</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:20.802659Z",
     "iopub.status.busy": "2025-04-25T12:59:20.802262Z",
     "iopub.status.idle": "2025-04-25T12:59:20.807002Z",
     "shell.execute_reply": "2025-04-25T12:59:20.806208Z",
     "shell.execute_reply.started": "2025-04-25T12:59:20.802631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Shortining_Service(url):\n",
    "    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
    "                      'tr\\.im|link\\.zip\\.net',\n",
    "                      url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "# A URL shortening service is a third-party website that converts that long URL to a short, \n",
    "# case-sensitive alphanumeric code. Simply put, this means that a URL shortening service takes \n",
    "# ridiculously long URLs (web addresses) and makes them short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:20.874715Z",
     "iopub.status.busy": "2025-04-25T12:59:20.874455Z",
     "iopub.status.idle": "2025-04-25T12:59:27.057114Z",
     "shell.execute_reply": "2025-04-25T12:59:27.056506Z",
     "shell.execute_reply.started": "2025-04-25T12:59:20.874692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['Shortining_Service'] = data['url'].apply(lambda x: Shortining_Service(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:27.059153Z",
     "iopub.status.busy": "2025-04-25T12:59:27.058724Z",
     "iopub.status.idle": "2025-04-25T12:59:27.081912Z",
     "shell.execute_reply": "2025-04-25T12:59:27.081274Z",
     "shell.execute_reply.started": "2025-04-25T12:59:27.059114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:27.082890Z",
     "iopub.status.busy": "2025-04-25T12:59:27.082715Z",
     "iopub.status.idle": "2025-04-25T12:59:27.291262Z",
     "shell.execute_reply": "2025-04-25T12:59:27.290564Z",
     "shell.execute_reply.started": "2025-04-25T12:59:27.082869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Shortining_Service', data=data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:29.943273Z",
     "iopub.status.busy": "2025-04-25T12:59:29.943013Z",
     "iopub.status.idle": "2025-04-25T12:59:29.947937Z",
     "shell.execute_reply": "2025-04-25T12:59:29.947187Z",
     "shell.execute_reply.started": "2025-04-25T12:59:29.943243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def having_ip_address(url):\n",
    "    match = re.search(\n",
    "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
    "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4 with port\n",
    "        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n",
    "        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}|'\n",
    "        '([0-9]+(?:\\.[0-9]+){3}:[0-9]+)|'\n",
    "        '((?:(?:\\d|[01]?\\d\\d|2[0-4]\\d|25[0-5])\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d|\\d)(?:\\/\\d{1,2})?)', url)  # Ipv6\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:31.893411Z",
     "iopub.status.busy": "2025-04-25T12:59:31.892843Z",
     "iopub.status.idle": "2025-04-25T12:59:43.795752Z",
     "shell.execute_reply": "2025-04-25T12:59:43.794921Z",
     "shell.execute_reply.started": "2025-04-25T12:59:31.893377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['having_ip_address'] = data['url'].apply(lambda i: having_ip_address(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:43.798211Z",
     "iopub.status.busy": "2025-04-25T12:59:43.797489Z",
     "iopub.status.idle": "2025-04-25T12:59:43.814491Z",
     "shell.execute_reply": "2025-04-25T12:59:43.813700Z",
     "shell.execute_reply.started": "2025-04-25T12:59:43.798170Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:43.815824Z",
     "iopub.status.busy": "2025-04-25T12:59:43.815492Z",
     "iopub.status.idle": "2025-04-25T12:59:43.829085Z",
     "shell.execute_reply": "2025-04-25T12:59:43.828404Z",
     "shell.execute_reply.started": "2025-04-25T12:59:43.815792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['having_ip_address'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:43.830549Z",
     "iopub.status.busy": "2025-04-25T12:59:43.830362Z",
     "iopub.status.idle": "2025-04-25T12:59:45.163311Z",
     "shell.execute_reply": "2025-04-25T12:59:45.162609Z",
     "shell.execute_reply.started": "2025-04-25T12:59:43.830525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(data.corr(), linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:45.164815Z",
     "iopub.status.busy": "2025-04-25T12:59:45.164562Z",
     "iopub.status.idle": "2025-04-25T12:59:45.324404Z",
     "shell.execute_reply": "2025-04-25T12:59:45.323859Z",
     "shell.execute_reply.started": "2025-04-25T12:59:45.164789Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['url','type','Category','domain'],axis=1)#,'type_code'\n",
    "y = data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:46.137319Z",
     "iopub.status.busy": "2025-04-25T12:59:46.137081Z",
     "iopub.status.idle": "2025-04-25T12:59:46.152288Z",
     "shell.execute_reply": "2025-04-25T12:59:46.151570Z",
     "shell.execute_reply.started": "2025-04-25T12:59:46.137291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:48.950043Z",
     "iopub.status.busy": "2025-04-25T12:59:48.949305Z",
     "iopub.status.idle": "2025-04-25T12:59:48.956584Z",
     "shell.execute_reply": "2025-04-25T12:59:48.955868Z",
     "shell.execute_reply.started": "2025-04-25T12:59:48.950005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "# ‚úÇÔ∏è Train & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:51.943634Z",
     "iopub.status.busy": "2025-04-25T12:59:51.943017Z",
     "iopub.status.idle": "2025-04-25T12:59:52.079152Z",
     "shell.execute_reply": "2025-04-25T12:59:52.078573Z",
     "shell.execute_reply.started": "2025-04-25T12:59:51.943586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:54.203287Z",
     "iopub.status.busy": "2025-04-25T12:59:54.202696Z",
     "iopub.status.idle": "2025-04-25T12:59:54.217301Z",
     "shell.execute_reply": "2025-04-25T12:59:54.216633Z",
     "shell.execute_reply.started": "2025-04-25T12:59:54.203256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:56.868361Z",
     "iopub.status.busy": "2025-04-25T12:59:56.867655Z",
     "iopub.status.idle": "2025-04-25T12:59:56.882410Z",
     "shell.execute_reply": "2025-04-25T12:59:56.881682Z",
     "shell.execute_reply.started": "2025-04-25T12:59:56.868330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T12:59:59.388046Z",
     "iopub.status.busy": "2025-04-25T12:59:59.387384Z",
     "iopub.status.idle": "2025-04-25T12:59:59.393863Z",
     "shell.execute_reply": "2025-04-25T12:59:59.393155Z",
     "shell.execute_reply.started": "2025-04-25T12:59:59.388010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T13:00:01.408009Z",
     "iopub.status.busy": "2025-04-25T13:00:01.407283Z",
     "iopub.status.idle": "2025-04-25T13:00:01.414107Z",
     "shell.execute_reply": "2025-04-25T13:00:01.413388Z",
     "shell.execute_reply.started": "2025-04-25T13:00:01.407972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> <br>\n",
    "# <img src=\"https://cdn-icons-png.flaticon.com/32/4149/4149680.png\"/> Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T13:00:04.680194Z",
     "iopub.status.busy": "2025-04-25T13:00:04.679941Z",
     "iopub.status.idle": "2025-04-25T13:00:04.683994Z",
     "shell.execute_reply": "2025-04-25T13:00:04.683242Z",
     "shell.execute_reply.started": "2025-04-25T13:00:04.680166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Updated model list\n",
    "models = [\n",
    "    AdaBoostClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    SGDClassifier,\n",
    "    GaussianNB,\n",
    "    MLPClassifier,\n",
    "    RidgeClassifier,\n",
    "    XGBClassifier\n",
    "]\n",
    "\n",
    "accuracy_test = []\n",
    "\n",
    "for m in models:\n",
    "    print('#############################################')\n",
    "    print('######-Model =>\\033[07m {} \\033[0m'.format(m.__name__))\n",
    "    model_ = m()\n",
    "    model_.fit(X_train, y_train)\n",
    "    pred = model_.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    accuracy_test.append(acc)\n",
    "    print('Test Accuracy :\\033[32m \\033[01m {:.2f}% \\033[30m \\033[0m'.format(acc*100))\n",
    "    print('\\033[01m              Classification_report \\033[0m')\n",
    "    print(classification_report(y_test, pred))\n",
    "    print('\\033[01m             Confusion_matrix \\033[0m')\n",
    "    cf_matrix = confusion_matrix(y_test, pred)\n",
    "    sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='0.2%')\n",
    "    plt.show()\n",
    "    print('\\033[31m###################- End -###################\\033[0m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        'AdaBoost Classifier',\n",
    "        'KNeighbors Classifier',\n",
    "        'SGD Classifier',\n",
    "        'Gaussian NB',\n",
    "        'MLP Classifier',\n",
    "        'Ridge Classifier',\n",
    "        'XGBoost Classifier'\n",
    "    ],\n",
    "    \"Accuracy\": accuracy_test\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:38:21.264916Z",
     "iopub.status.busy": "2025-04-25T08:38:21.264636Z",
     "iopub.status.idle": "2025-04-25T08:38:21.280891Z",
     "shell.execute_reply": "2025-04-25T08:38:21.280011Z",
     "shell.execute_reply.started": "2025-04-25T08:38:21.264886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plots = sns.barplot(x='Model', y='Accuracy', data=output)\n",
    "for bar in plots.patches:\n",
    "    plots.annotate(format(bar.get_height(), '.2f'),\n",
    "                   (bar.get_x() + bar.get_width() / 2,\n",
    "                    bar.get_height()), ha='center', va='center',\n",
    "                   size=15, xytext=(0, 8),\n",
    "                   textcoords='offset points')\n",
    "\n",
    "plt.xlabel(\"Models\", size=14)\n",
    "plt.xticks(rotation=20);\n",
    "plt.ylabel(\"Accuracy\", size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def URL_Converter(urls):\n",
    "    data= pd.DataFrame()\n",
    "    data['url'] = pd.Series(urls)\n",
    "\n",
    "    \n",
    "    data['url_len'] = data['url'].apply(lambda x: len(str(x)))\n",
    "    data['domain'] = data['url'].apply(lambda i: process_tld(i))\n",
    "    feature = ['@','?','-','=','.','#','%','+','$','!','*',',','//']\n",
    "    for a in feature:\n",
    "        data[a] = data['url'].apply(lambda i: i.count(a))  \n",
    "    data['abnormal_url'] = data['url'].apply(lambda i: abnormal_url(i))\n",
    "    data['https'] = data['url'].apply(lambda i: httpSecure(i))\n",
    "    data['digits']= data['url'].apply(lambda i: digit_count(i))\n",
    "    data['letters']= data['url'].apply(lambda i: letter_count(i))\n",
    "    data['Shortining_Service'] = data['url'].apply(lambda x: Shortining_Service(x))\n",
    "    data['having_ip_address'] = data['url'].apply(lambda i: having_ip_address(i))\n",
    "    print(data.columns)\n",
    "    X = data.drop(['url','domain'],axis=1)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "urls= ['diaryofagameaddict.com',\n",
    "'espdesign.com.au',\n",
    "'iamagameaddict.com',\n",
    "'kalantzis.net',\n",
    "'slightlyoffcenter.net',\n",
    "'toddscarwash.com',\n",
    "'tubemoviez.com',\n",
    "'ipl.hk',\n",
    "'crackspider.us/toolbar/install.php?pack=exe',\n",
    "'pos-kupang.com/',\n",
    "'rupor.info',\n",
    "'svision-online.de/mgfi/administrator/components/com_babackup/classes/fx29id1.txt',\n",
    "'officeon.ch.ma/office.js?google_ad_format=728x90_as',\n",
    "'sn-gzzx.com',\n",
    "'sunlux.net/company/about.html',\n",
    "'outporn.com',\n",
    "'timothycopus.aimoo.com',\n",
    "'xindalawyer.com',\n",
    "'freeserials.spb.ru/key/68703.htm',\n",
    "'deletespyware-adware.com',\n",
    "'orbowlada.strefa.pl/text396.htm',\n",
    "'ruiyangcn.com',\n",
    "'zkic.com',\n",
    "'adserving.favorit-network.com/eas?camp=19320;cre=mu&grpid=1738&tag_id=618&nums=FGApbjFAAA',\n",
    "'cracks.vg/d1.php',\n",
    "'juicypussyclips.com',\n",
    "'nuptialimages.com',\n",
    "'andysgame.com',\n",
    "'bezproudoff.cz',\n",
    "'ceskarepublika.net',\n",
    "'hotspot.cz',\n",
    "'gmcjjh.org/DHL',\n",
    "'nerez-schodiste-zabradli.com',\n",
    "'nordiccountry.cz',\n",
    "'nowina.info',\n",
    "'obada-konstruktiwa.org',\n",
    "'otylkaaotesanek.cz',\n",
    "'pb-webdesign.net',\n",
    "'pension-helene.cz',\n",
    "'podzemi.myotis.info',\n",
    "'smrcek.com',\n",
    "'spekband.com',\n",
    "'m2132.ehgaugysd.net/zyso.cgi?18',\n",
    "'webcom-software.ws/links/?153646e8b0a88',\n",
    "'worldgymperu.com',\n",
    "'zgsysz.com',\n",
    "'oknarai.ru',\n",
    "'realinnovation.com/css/menu.js']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_data= URL_Converter(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    print('#############################################')\n",
    "    print('######-Model =>\\033[07m {} \\033[0m'.format(m))\n",
    "    model_ = m()\n",
    "    model_.fit(X_train, y_train)\n",
    "    pred = model_.predict(test_data)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8 - Final Rreport**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        'AdaBoost Classifier',\n",
    "        'KNeighbors Classifier',\n",
    "        'SGD Classifier',\n",
    "        'Gaussian NB',\n",
    "        'MLP Classifier',\n",
    "        'Ridge Classifier',\n",
    "        'XGBoost Classifier'\n",
    "    ],\n",
    "    \"Accuracy\": accuracy_test\n",
    "})\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:11:44.876622Z",
     "iopub.status.busy": "2025-04-25T08:11:44.876340Z",
     "iopub.status.idle": "2025-04-25T08:12:02.197889Z",
     "shell.execute_reply": "2025-04-25T08:12:02.196819Z",
     "shell.execute_reply.started": "2025-04-25T08:11:44.876588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create directory to save models\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "# Save each trained model\n",
    "for i, m in enumerate(models):\n",
    "    model_name = m.__name__\n",
    "    model_instance = m()\n",
    "    model_instance.fit(X_train, y_train)\n",
    "    joblib.dump(model_instance, f\"saved_models/{model_name}.pkl\")\n",
    "    print(f\"‚úÖ Saved: saved_models/{model_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Folder you want to zip\n",
    "folder_to_zip = '/kaggle/working/saved_models'\n",
    "zip_filename = '/kaggle/working/saved_models.zip'\n",
    "\n",
    "# Create ZIP file\n",
    "shutil.make_archive(base_name=zip_filename.replace('.zip', ''), format='zip', root_dir=folder_to_zip)\n",
    "\n",
    "print(f\"‚úÖ Folder '{folder_to_zip}' zipped as '{zip_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T08:58:32.525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:39:19.654471Z",
     "iopub.status.busy": "2025-04-25T08:39:19.654214Z",
     "iopub.status.idle": "2025-04-25T08:45:27.248666Z",
     "shell.execute_reply": "2025-04-25T08:45:27.247615Z",
     "shell.execute_reply.started": "2025-04-25T08:39:19.654443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# === Clean column names to remove special characters ===\n",
    "X_train.columns = [re.sub(r'[^\\w\\s]', '_', str(col)) for col in X_train.columns]\n",
    "X_test.columns = [re.sub(r'[^\\w\\s]', '_', str(col)) for col in X_test.columns]\n",
    "\n",
    "# === DL setup for raw URL sequences ===\n",
    "MAX_LEN = 100\n",
    "VOCAB_SIZE = 1000\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True, lower=True, num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(X_train)  # separate raw URL text\n",
    "X_seq_train = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=MAX_LEN)\n",
    "X_seq_test = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=MAX_LEN)\n",
    "\n",
    "# === DL Model ===\n",
    "def build_dl_model():\n",
    "    model = Sequential([\n",
    "        Embedding(VOCAB_SIZE, 32, input_length=MAX_LEN),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === ML Model Evaluation ===\n",
    "accuracy_test = []\n",
    "model_names = []\n",
    "\n",
    "ml_models = [\n",
    "    ('Random Forest Classifier', RandomForestClassifier()),\n",
    "    ('Gradient Boosting Classifier', GradientBoostingClassifier()),\n",
    "    ('Extra Trees Classifier', ExtraTreesClassifier()),\n",
    "    ('Logistic Regression', LogisticRegression(solver='liblinear')),\n",
    "    ('LGBM Classifier', LGBMClassifier()),\n",
    "    ('CatBoost Classifier', CatBoostClassifier(verbose=0))\n",
    "]\n",
    "\n",
    "for name, model in ml_models:\n",
    "    print('#############################################')\n",
    "    print(f'######-Model => \\033[07m {name} \\033[0m')\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        accuracy_test.append(acc)\n",
    "        model_names.append(name)\n",
    "        print(f'Test Accuracy :\\033[32m \\033[01m {acc * 100:.2f}% \\033[0m')\n",
    "        print('\\033[01mClassification Report:\\033[0m')\n",
    "        print(classification_report(y_test, pred))\n",
    "        print('\\033[01mConfusion Matrix:\\033[0m')\n",
    "        cf_matrix = confusion_matrix(y_test, pred)\n",
    "        sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='0.2%')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error with model {name}: {e}\")\n",
    "    print('\\033[31m###################- End -###################\\033[0m')\n",
    "\n",
    "# === DL Model Training ===\n",
    "print('\\n\\033[34m############### Training Deep Learning Model ###############\\033[0m')\n",
    "dl_model = build_dl_model()\n",
    "dl_model.fit(X_seq_train, y_train, epochs=5, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "dl_pred_probs = dl_model.predict(X_seq_test)\n",
    "dl_preds = (dl_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "acc_dl = accuracy_score(y_test, dl_preds)\n",
    "print('\\033[32mDL Test Accuracy: {:.2f}%\\033[0m'.format(acc_dl * 100))\n",
    "print(classification_report(y_test, dl_preds))\n",
    "sns.heatmap(confusion_matrix(y_test, dl_preds) / np.sum(confusion_matrix(y_test, dl_preds)), annot=True, fmt='0.2%')\n",
    "plt.show()\n",
    "\n",
    "# Add DL model to output\n",
    "model_names.append(\"Deep Learning Model (CNN)\")\n",
    "accuracy_test.append(acc_dl)\n",
    "\n",
    "# === Hybrid Model (Stack ML + DL) ===\n",
    "print('\\n\\033[36m############### Hybrid Model (Stacked) ###############\\033[0m')\n",
    "\n",
    "base_learners = [\n",
    "    ('lgbm', LGBMClassifier()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "stack_model = StackingClassifier(estimators=base_learners, final_estimator=meta_model)\n",
    "stack_model.fit(X_train, y_train)\n",
    "stack_pred = stack_model.predict(X_test)\n",
    "\n",
    "combined_preds = ((stack_pred + dl_preds) > 1).astype(int)\n",
    "\n",
    "acc_combined = accuracy_score(y_test, combined_preds)\n",
    "print('\\033[35mHybrid Accuracy (DL + ML): {:.2f}%\\033[0m'.format(acc_combined * 100))\n",
    "print(classification_report(y_test, combined_preds))\n",
    "sns.heatmap(confusion_matrix(y_test, combined_preds) / np.sum(confusion_matrix(y_test, combined_preds)), annot=True, fmt='0.2%')\n",
    "plt.show()\n",
    "\n",
    "# Add Hybrid model to output\n",
    "model_names.append(\"Hybrid Model (Stacked + DL)\")\n",
    "accuracy_test.append(acc_combined)\n",
    "\n",
    "# === Final Output Table ===\n",
    "output = pd.DataFrame({\"Model\": model_names, \"Accuracy\": accuracy_test})\n",
    "print(\"\\n\\033[01mFinal Accuracy Summary:\\033[0m\")\n",
    "print(output.sort_values(by=\"Accuracy\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T09:01:20.367753Z",
     "iopub.status.busy": "2025-04-24T09:01:20.366866Z",
     "iopub.status.idle": "2025-04-24T09:10:30.589189Z",
     "shell.execute_reply": "2025-04-24T09:10:30.588144Z",
     "shell.execute_reply.started": "2025-04-24T09:01:20.367711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# === Deep Learning Tokenization ===\n",
    "MAX_LEN = 100\n",
    "VOCAB_SIZE = 1000\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True, lower=True, num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(X_train)  # X_raw_train: list of raw URL strings\n",
    "\n",
    "X_seq_train = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=MAX_LEN)\n",
    "X_seq_test = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=MAX_LEN)\n",
    "\n",
    "# === Deep Learning Model ===\n",
    "def build_dl_model():\n",
    "    model = Sequential([\n",
    "        Embedding(VOCAB_SIZE, 32, input_length=MAX_LEN),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === ML Model List ===\n",
    "models = [\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    LogisticRegression,\n",
    "    LGBMClassifier,\n",
    "    CatBoostClassifier\n",
    "]\n",
    "\n",
    "# === Train and Evaluate ML Models ===\n",
    "accuracy_test = []\n",
    "\n",
    "for m in models:\n",
    "    print('#############################################')\n",
    "    print(f'######-Model =>\\033[07m {m.__name__} \\033[0m')\n",
    "    try:\n",
    "        model_ = m()\n",
    "        model_.fit(X_train, y_train)\n",
    "        pred = model_.predict(X_test)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        accuracy_test.append(acc)\n",
    "        print(f'Test Accuracy :\\033[32m \\033[01m {acc*100:.2f}% \\033[0m')\n",
    "        print('\\033[01mClassification Report:\\033[0m')\n",
    "        print(classification_report(y_test, pred))\n",
    "        print('\\033[01mConfusion Matrix:\\033[0m')\n",
    "        cf_matrix = confusion_matrix(y_test, pred)\n",
    "        sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='0.2%')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error with model {m.__name__}: {e}\")\n",
    "    print('\\033[31m###################- End -###################\\033[0m')\n",
    "\n",
    "# === Train and Evaluate DL Model ===\n",
    "print('\\n\\033[34m############### Training Deep Learning Model ###############\\033[0m')\n",
    "dl_model = build_dl_model()\n",
    "dl_model.fit(X_seq_train, y_train, epochs=5, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "dl_pred_probs = dl_model.predict(X_seq_test)\n",
    "dl_preds = (dl_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "acc_dl = accuracy_score(y_test, dl_preds)\n",
    "print('\\033[32mDL Test Accuracy: {:.2f}%\\033[0m'.format(acc_dl * 100))\n",
    "print(classification_report(y_test, dl_preds))\n",
    "sns.heatmap(confusion_matrix(y_test, dl_preds) / np.sum(confusion_matrix(y_test, dl_preds)), annot=True, fmt='0.2%')\n",
    "plt.show()\n",
    "\n",
    "# === Hybrid Stacked Model ===\n",
    "print('\\n\\033[36m############### Hybrid Model (Stacked ML + DL) ###############\\033[0m')\n",
    "\n",
    "# Base ML models\n",
    "base_learners = [\n",
    "    ('lgbm', LGBMClassifier()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "stack_model = StackingClassifier(estimators=base_learners, final_estimator=meta_model)\n",
    "stack_model.fit(X_train, y_train)\n",
    "stack_pred = stack_model.predict(X_test)\n",
    "\n",
    "# Combine DL + Stacking\n",
    "combined_preds = ((stack_pred + dl_preds) > 1).astype(int)\n",
    "\n",
    "acc_combined = accuracy_score(y_test, combined_preds)\n",
    "print('\\033[35mHybrid Accuracy (DL + ML): {:.2f}%\\033[0m'.format(acc_combined * 100))\n",
    "print(classification_report(y_test, combined_preds))\n",
    "sns.heatmap(confusion_matrix(y_test, combined_preds) / np.sum(confusion_matrix(y_test, combined_preds)), annot=True, fmt='0.2%')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T09:46:38.067920Z",
     "iopub.status.busy": "2025-04-25T09:46:38.067649Z",
     "iopub.status.idle": "2025-04-25T09:47:00.201602Z",
     "shell.execute_reply": "2025-04-25T09:47:00.200938Z",
     "shell.execute_reply.started": "2025-04-25T09:46:38.067892Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm catboost xgboost tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T13:00:56.108441Z",
     "iopub.status.busy": "2025-04-25T13:00:56.108184Z",
     "iopub.status.idle": "2025-04-25T13:01:03.782236Z",
     "shell.execute_reply": "2025-04-25T13:01:03.781670Z",
     "shell.execute_reply.started": "2025-04-25T13:00:56.108412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Re-import DL tools if needed\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T13:01:08.008514Z",
     "iopub.status.busy": "2025-04-25T13:01:08.007821Z",
     "iopub.status.idle": "2025-04-25T13:01:08.135777Z",
     "shell.execute_reply": "2025-04-25T13:01:08.134945Z",
     "shell.execute_reply.started": "2025-04-25T13:01:08.008479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Scale X for DL models\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T13:01:10.032860Z",
     "iopub.status.busy": "2025-04-25T13:01:10.032128Z",
     "iopub.status.idle": "2025-04-25T13:01:10.089524Z",
     "shell.execute_reply": "2025-04-25T13:01:10.088990Z",
     "shell.execute_reply.started": "2025-04-25T13:01:10.032825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_dl = np.array(X_scaled)\n",
    "y_dl = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T13:01:12.603218Z",
     "iopub.status.busy": "2025-04-25T13:01:12.602453Z",
     "iopub.status.idle": "2025-04-25T13:01:12.792584Z",
     "shell.execute_reply": "2025-04-25T13:01:12.792033Z",
     "shell.execute_reply.started": "2025-04-25T13:01:12.603181Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Splits again for DL usage\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_dl, y_dl, test_size=0.2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T10:38:42.954706Z",
     "iopub.status.busy": "2025-04-25T10:38:42.954370Z",
     "iopub.status.idle": "2025-04-25T10:38:42.960720Z",
     "shell.execute_reply": "2025-04-25T10:38:42.959675Z",
     "shell.execute_reply.started": "2025-04-25T10:38:42.954676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Machine Learning models\n",
    "ml_models = {\n",
    "    'LogisticRegression': LogisticRegression(solver='liblinear', max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T10:38:49.613998Z",
     "iopub.status.busy": "2025-04-25T10:38:49.613757Z",
     "iopub.status.idle": "2025-04-25T10:38:49.617619Z",
     "shell.execute_reply": "2025-04-25T10:38:49.616826Z",
     "shell.execute_reply.started": "2025-04-25T10:38:49.613972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "accuracy_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T10:44:20.599604Z",
     "iopub.status.busy": "2025-04-25T10:44:20.599081Z",
     "iopub.status.idle": "2025-04-25T10:49:36.975437Z",
     "shell.execute_reply": "2025-04-25T10:49:36.974669Z",
     "shell.execute_reply.started": "2025-04-25T10:44:20.599563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "for name, model in ml_models.items():\n",
    "    print('#############################################')\n",
    "    print(f'######-Model =>\\033[07m {name} \\033[0m')\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    accuracy_test.append(acc)\n",
    "    print('Test Accuracy :\\033[32m \\033[01m {:.2f}% \\033[30m \\033[0m'.format(acc*100))\n",
    "    print('\\033[01m              Classification_report \\033[0m')\n",
    "    print(classification_report(y_test, pred))\n",
    "    print('\\033[01m             Confusion_matrix \\033[0m')\n",
    "    cf_matrix = confusion_matrix(y_test, pred)\n",
    "    sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='0.2%')\n",
    "    plt.show()\n",
    "    print('\\033[31m###################- End -###################\\033[0m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T10:54:34.464362Z",
     "iopub.status.busy": "2025-04-25T10:54:34.463808Z",
     "iopub.status.idle": "2025-04-25T11:01:18.597037Z",
     "shell.execute_reply": "2025-04-25T11:01:18.596282Z",
     "shell.execute_reply.started": "2025-04-25T10:54:34.464324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Feed Forward Neural Network (MLP)\n",
    "def build_mlp(input_dim, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"Training MLP Neural Network...\")\n",
    "mlp_model = build_mlp(X_train_dl.shape[1], y_dl.shape[1])\n",
    "mlp_model.fit(X_train_dl, y_train_dl, epochs=10, batch_size=32, verbose=1, validation_data=(X_test_dl, y_test_dl))\n",
    "loss, acc = mlp_model.evaluate(X_test_dl, y_test_dl, verbose=0)\n",
    "print(f\"MLP Accuracy: \\033[32m{acc*100:.2f}%\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T11:01:35.603599Z",
     "iopub.status.busy": "2025-04-25T11:01:35.602849Z",
     "iopub.status.idle": "2025-04-25T11:09:13.795442Z",
     "shell.execute_reply": "2025-04-25T11:09:13.794642Z",
     "shell.execute_reply.started": "2025-04-25T11:01:35.603564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CNN model\n",
    "X_cnn = X_dl.reshape(X_dl.shape[0], X_dl.shape[1], 1)\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y_dl, test_size=0.2, random_state=2)\n",
    "\n",
    "def build_cnn(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"Training CNN model...\")\n",
    "cnn_model = build_cnn((X_cnn.shape[1], 1), y_dl.shape[1])\n",
    "cnn_model.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=32, validation_data=(X_test_cnn, y_test_cnn), verbose=1)\n",
    "loss, acc = cnn_model.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
    "print(f\"CNN Accuracy: \\033[32m{acc*100:.2f}%\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T11:09:44.563088Z",
     "iopub.status.busy": "2025-04-25T11:09:44.562851Z",
     "iopub.status.idle": "2025-04-25T11:16:57.274045Z",
     "shell.execute_reply": "2025-04-25T11:16:57.273389Z",
     "shell.execute_reply.started": "2025-04-25T11:09:44.563063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ------------------------ HYBRID (DL Features + ML Classifier) ------------------------ #\n",
    "# Example: Use last hidden layer of MLP as input to XGBoost\n",
    "from keras.models import Model\n",
    "\n",
    "extract_model = Model(inputs=mlp_model.input, outputs=mlp_model.layers[-2].output)\n",
    "X_train_feats = extract_model.predict(X_train_dl)\n",
    "X_test_feats = extract_model.predict(X_test_dl)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "y_train_mapped = np.argmax(y_train_dl, axis=1)\n",
    "y_test_mapped = np.argmax(y_test_dl, axis=1)\n",
    "xgb.fit(X_train_feats, y_train_mapped)\n",
    "pred = xgb.predict(X_test_feats)\n",
    "\n",
    "acc = accuracy_score(y_test_mapped, pred)\n",
    "print(f\"Hybrid DL+ML (MLP + XGBoost) Accuracy: \\033[35m{acc*100:.2f}%\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T13:01:29.643566Z",
     "iopub.status.busy": "2025-04-25T13:01:29.643308Z",
     "iopub.status.idle": "2025-04-25T13:01:52.726363Z",
     "shell.execute_reply": "2025-04-25T13:01:52.725799Z",
     "shell.execute_reply.started": "2025-04-25T13:01:29.643534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use the correct DataFrame and column\n",
    "text_column = 'url'  # character-tokenize the 'url' column\n",
    "\n",
    "# Character-level tokenization\n",
    "char_tokenizer = Tokenizer(char_level=True)\n",
    "char_tokenizer.fit_on_texts(data[text_column].astype(str))\n",
    "\n",
    "# Convert to sequences and pad\n",
    "sequences = char_tokenizer.texts_to_sequences(data[text_column].astype(str))\n",
    "MAX_LEN = 300  # You can adjust based on URL length distribution\n",
    "X_char = pad_sequences(sequences, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "# Target variable\n",
    "y_char = to_categorical(data['Category'])  # assuming 'Category' is the label\n",
    "\n",
    "# Train-test split\n",
    "X_train_char, X_test_char, y_train_char, y_test_char = train_test_split(\n",
    "    X_char, y_char, test_size=0.2, random_state=2\n",
    ")\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(char_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T13:01:52.727751Z",
     "iopub.status.busy": "2025-04-25T13:01:52.727520Z",
     "iopub.status.idle": "2025-04-25T13:48:46.580669Z",
     "shell.execute_reply": "2025-04-25T13:48:46.579875Z",
     "shell.execute_reply.started": "2025-04-25T13:01:52.727721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=MAX_LEN))\n",
    "lstm_model.add(LSTM(128, return_sequences=False))\n",
    "lstm_model.add(Dropout(0.3))\n",
    "lstm_model.add(Dense(64, activation='relu'))\n",
    "lstm_model.add(Dense(y_char.shape[1], activation='softmax'))\n",
    "\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"Training LSTM model...\")\n",
    "lstm_model.fit(X_train_char, y_train_char, epochs=10, batch_size=32, validation_data=(X_test_char, y_test_char), verbose=1)\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = lstm_model.evaluate(X_test_char, y_test_char, verbose=0)\n",
    "print(f\"\\033[36mLSTM Accuracy (Char-level): {acc*100:.2f}%\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T13:52:59.223953Z",
     "iopub.status.busy": "2025-04-25T13:52:59.223201Z",
     "iopub.status.idle": "2025-04-25T13:53:23.333414Z",
     "shell.execute_reply": "2025-04-25T13:53:23.332796Z",
     "shell.execute_reply.started": "2025-04-25T13:52:59.223913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Predict class labels from the model\n",
    "y_pred_probs = lstm_model.predict(X_test_char)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test_char, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - LSTM (Char-level)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: Classification report\n",
    "print(\"\\033[01mClassification Report:\\033[0m\")\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:06:42.118326Z",
     "iopub.status.busy": "2025-04-25T16:06:42.118075Z",
     "iopub.status.idle": "2025-04-25T16:06:42.149337Z",
     "shell.execute_reply": "2025-04-25T16:06:42.148570Z",
     "shell.execute_reply.started": "2025-04-25T16:06:42.118298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "lstm_model.save('cnn_lstm_model.h5')  # You can change the name as needed\n",
    "print(\"Model saved to 'cnn_lstm_model.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T14:10:48.283448Z",
     "iopub.status.busy": "2025-04-25T14:10:48.283189Z",
     "iopub.status.idle": "2025-04-25T14:11:12.133057Z",
     "shell.execute_reply": "2025-04-25T14:11:12.132347Z",
     "shell.execute_reply.started": "2025-04-25T14:10:48.283419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Predict class labels from the LSTM model\n",
    "y_pred_probs = lstm_model.predict(X_test_char)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test_char, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "print('\\033[01m             Confusion_matrix \\033[0m')\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Normalize and plot the confusion matrix\n",
    "sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='0.2%', cmap='Blues')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Optional: Classification report\n",
    "print(\"\\033[01mClassification Report:\\033[0m\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# End of Confusion Matrix\n",
    "print('\\033[31m###################- End -###################\\033[0m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T14:32:31.598913Z",
     "iopub.status.busy": "2025-04-25T14:32:31.598604Z",
     "iopub.status.idle": "2025-04-25T14:32:31.709138Z",
     "shell.execute_reply": "2025-04-25T14:32:31.708397Z",
     "shell.execute_reply.started": "2025-04-25T14:32:31.598881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Store LSTM accuracy from earlier\n",
    "lstm_accuracy = acc  # assuming `acc` is already defined from LSTM evaluation\n",
    "\n",
    "# 2. Create DataFrame for LSTM only\n",
    "output = pd.DataFrame({\n",
    "    \"Model\": ['LSTM (Char-level)'],\n",
    "    \"Accuracy\": [lstm_accuracy]\n",
    "})\n",
    "\n",
    "# 3. Plot accuracy\n",
    "plt.figure(figsize=(6, 4))\n",
    "plot = sns.barplot(x='Model', y='Accuracy', data=output, palette='Blues_d')\n",
    "for bar in plot.patches:\n",
    "    plot.annotate(format(bar.get_height(), '.2f'),\n",
    "                  (bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                  ha='center', va='center', size=14, xytext=(0, 8),\n",
    "                  textcoords='offset points')\n",
    "\n",
    "plt.xlabel(\"Model\", size=12)\n",
    "plt.ylabel(\"Accuracy\", size=12)\n",
    "plt.title(\"LSTM Model Accuracy\", size=14)\n",
    "plt.ylim(0, 1)  # Accuracy ranges from 0 to 1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T14:33:15.977840Z",
     "iopub.status.busy": "2025-04-25T14:33:15.977173Z",
     "iopub.status.idle": "2025-04-25T14:33:15.983116Z",
     "shell.execute_reply": "2025-04-25T14:33:15.982315Z",
     "shell.execute_reply.started": "2025-04-25T14:33:15.977808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test URLs\n",
    "urls = [\n",
    "    'diaryofagameaddict.com',\n",
    "'espdesign.com.au',\n",
    "'iamagameaddict.com',\n",
    "'kalantzis.net',\n",
    "'slightlyoffcenter.net',\n",
    "'toddscarwash.com',\n",
    "'tubemoviez.com',\n",
    "'ipl.hk',\n",
    "'crackspider.us/toolbar/install.php?pack=exe',\n",
    "'pos-kupang.com/',\n",
    "'rupor.info',\n",
    "'svision-online.de/mgfi/administrator/components/com_babackup/classes/fx29id1.txt',\n",
    "'officeon.ch.ma/office.js?google_ad_format=728x90_as',\n",
    "'sn-gzzx.com',\n",
    "'sunlux.net/company/about.html',\n",
    "'outporn.com',\n",
    "'timothycopus.aimoo.com',\n",
    "'xindalawyer.com',\n",
    "'freeserials.spb.ru/key/68703.htm',\n",
    "'deletespyware-adware.com',\n",
    "'orbowlada.strefa.pl/text396.htm',\n",
    "'ruiyangcn.com',\n",
    "'zkic.com',\n",
    "'adserving.favorit-network.com/eas?camp=19320;cre=mu&grpid=1738&tag_id=618&nums=FGApbjFAAA',\n",
    "'cracks.vg/d1.php',\n",
    "'juicypussyclips.com',\n",
    "'nuptialimages.com',\n",
    "'andysgame.com',\n",
    "'bezproudoff.cz',\n",
    "'ceskarepublika.net',\n",
    "'hotspot.cz',\n",
    "'gmcjjh.org/DHL',\n",
    "'nerez-schodiste-zabradli.com',\n",
    "'nordiccountry.cz',\n",
    "'nowina.info',\n",
    "'obada-konstruktiwa.org',\n",
    "'otylkaaotesanek.cz',\n",
    "'pb-webdesign.net',\n",
    "'pension-helene.cz',\n",
    "'podzemi.myotis.info',\n",
    "'smrcek.com',\n",
    "'spekband.com',\n",
    "'m2132.ehgaugysd.net/zyso.cgi?18',\n",
    "'webcom-software.ws/links/?153646e8b0a88',\n",
    "'worldgymperu.com',\n",
    "'zgsysz.com',\n",
    "'oknarai.ru',\n",
    "'realinnovation.com/css/menu.js'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T14:33:18.917578Z",
     "iopub.status.busy": "2025-04-25T14:33:18.917018Z",
     "iopub.status.idle": "2025-04-25T14:33:18.983210Z",
     "shell.execute_reply": "2025-04-25T14:33:18.982512Z",
     "shell.execute_reply.started": "2025-04-25T14:33:18.917546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert URLs to character-level sequences\n",
    "test_sequences = char_tokenizer.texts_to_sequences(urls)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "# Predict using trained LSTM model\n",
    "predictions = lstm_model.predict(test_padded)\n",
    "predicted_classes = predictions.argmax(axis=1)\n",
    "\n",
    "# Output predictions\n",
    "for url, pred_class in zip(urls, predicted_classes):\n",
    "    print(f\"URL: {url} --> Predicted Class: {pred_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T14:34:22.467674Z",
     "iopub.status.busy": "2025-04-25T14:34:22.467110Z",
     "iopub.status.idle": "2025-04-25T14:34:22.532718Z",
     "shell.execute_reply": "2025-04-25T14:34:22.531886Z",
     "shell.execute_reply.started": "2025-04-25T14:34:22.467642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('#############################################')\n",
    "print('######-Model =>\\033[07m LSTM (Char-level) \\033[0m')\n",
    "\n",
    "# Convert URLs into char-level sequences\n",
    "test_sequences = char_tokenizer.texts_to_sequences(urls)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "# Predict\n",
    "pred_probs = lstm_model.predict(test_padded)\n",
    "predicted_classes = pred_probs.argmax(axis=1)\n",
    "\n",
    "# Output predictions\n",
    "for url, pred_class in zip(urls, predicted_classes):\n",
    "    print(f\"URL: {url} --> Predicted Class: {pred_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T14:36:07.459746Z",
     "iopub.status.busy": "2025-04-25T14:36:07.459079Z",
     "iopub.status.idle": "2025-04-25T15:05:35.606154Z",
     "shell.execute_reply": "2025-04-25T15:05:35.605320Z",
     "shell.execute_reply.started": "2025-04-25T14:36:07.459711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define model\n",
    "cnn_lstm_model = Sequential()\n",
    "cnn_lstm_model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=MAX_LEN))\n",
    "cnn_lstm_model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "cnn_lstm_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_lstm_model.add(LSTM(64, return_sequences=False))\n",
    "cnn_lstm_model.add(Dropout(0.3))\n",
    "cnn_lstm_model.add(Dense(64, activation='relu'))\n",
    "cnn_lstm_model.add(Dense(y_char.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "cnn_lstm_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "print(\"Training CNN + LSTM model...\")\n",
    "cnn_lstm_model.fit(X_train_char, y_train_char, epochs=10, batch_size=32, validation_data=(X_test_char, y_test_char), verbose=1)\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = cnn_lstm_model.evaluate(X_test_char, y_test_char, verbose=0)\n",
    "print(f\"\\033[36mCNN + LSTM Accuracy (Char-level): {acc*100:.2f}%\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T15:05:52.903938Z",
     "iopub.status.busy": "2025-04-25T15:05:52.903703Z",
     "iopub.status.idle": "2025-04-25T15:05:53.271972Z",
     "shell.execute_reply": "2025-04-25T15:05:53.271139Z",
     "shell.execute_reply.started": "2025-04-25T15:05:52.903914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('#############################################')\n",
    "print('######-Model =>\\033[07m CNN + LSTM (Char-level) \\033[0m')\n",
    "\n",
    "# Prepare input\n",
    "test_sequences = char_tokenizer.texts_to_sequences(urls)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "# Predict\n",
    "pred_probs = cnn_lstm_model.predict(test_padded)\n",
    "predicted_classes = pred_probs.argmax(axis=1)\n",
    "\n",
    "# Output\n",
    "for url, pred_class in zip(urls, predicted_classes):\n",
    "    print(f\"URL: {url} --> Predicted Class: {pred_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T15:07:18.874005Z",
     "iopub.status.busy": "2025-04-25T15:07:18.873300Z",
     "iopub.status.idle": "2025-04-25T15:07:33.502746Z",
     "shell.execute_reply": "2025-04-25T15:07:33.502059Z",
     "shell.execute_reply.started": "2025-04-25T15:07:18.873960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Predict class labels from the LSTM model\n",
    "y_pred_probs = cnn_lstm_model.predict(X_test_char)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test_char, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "print('\\033[01m             Confusion_matrix \\033[0m')\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Normalize and plot the confusion matrix\n",
    "sns.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='0.2%', cmap='Blues')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Optional: Classification report\n",
    "print(\"\\033[01mClassification Report:\\033[0m\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# End of Confusion Matrix\n",
    "print('\\033[31m###################- End -###################\\033[0m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T15:12:19.143107Z",
     "iopub.status.busy": "2025-04-25T15:12:19.142251Z",
     "iopub.status.idle": "2025-04-25T15:12:19.147056Z",
     "shell.execute_reply": "2025-04-25T15:12:19.146283Z",
     "shell.execute_reply.started": "2025-04-25T15:12:19.143071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LayerNormalization, Dropout\n",
    "from tensorflow.keras.layers import MultiHeadAttention, GlobalAveragePooling1D, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T15:13:38.458268Z",
     "iopub.status.busy": "2025-04-25T15:13:38.457558Z",
     "iopub.status.idle": "2025-04-25T15:13:38.469685Z",
     "shell.execute_reply": "2025-04-25T15:13:38.468947Z",
     "shell.execute_reply.started": "2025-04-25T15:13:38.458217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Positional Encoding ---\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "        pos = np.arange(max_len)[:, np.newaxis]\n",
    "        i = np.arange(d_model)[np.newaxis, :]\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "        angle_rads = pos * angle_rates\n",
    "\n",
    "        # Apply sin to even indices; cos to odd\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        self.pos_encoding = tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n",
    "\n",
    "# --- Transformer Block ---\n",
    "def transformer_block(x, num_heads, ff_dim, dropout=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=ff_dim)(x, x)\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation='relu')(out1)\n",
    "    ff_output = Dense(x.shape[-1])(ff_output)\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    return LayerNormalization(epsilon=1e-6)(out1 + ff_output)\n",
    "\n",
    "# --- Build Model ---\n",
    "def build_transformer_model(vocab_size, max_len, num_classes):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=128)(inputs)\n",
    "    x = PositionalEncoding(max_len, 128)(x)\n",
    "    x = transformer_block(x, num_heads=2, ff_dim=64, dropout=0.1)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:07:13.674851Z",
     "iopub.status.busy": "2025-04-25T16:07:13.674302Z",
     "iopub.status.idle": "2025-04-25T17:21:03.462537Z",
     "shell.execute_reply": "2025-04-25T17:21:03.461658Z",
     "shell.execute_reply.started": "2025-04-25T16:07:13.674820Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Instantiate and Compile ---\n",
    "transformer_model = build_transformer_model(vocab_size, MAX_LEN, y_char.shape[1])\n",
    "transformer_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# --- Train ---\n",
    "print(\"\\033[34mTraining Transformer Model...\\033[0m\")\n",
    "transformer_model.fit(X_train_char, y_train_char, \n",
    "                      epochs=20, batch_size=32, \n",
    "                      validation_data=(X_test_char, y_test_char),\n",
    "                      callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)],\n",
    "                      verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T17:21:17.707356Z",
     "iopub.status.busy": "2025-04-25T17:21:17.706776Z",
     "iopub.status.idle": "2025-04-25T17:21:37.749845Z",
     "shell.execute_reply": "2025-04-25T17:21:37.749011Z",
     "shell.execute_reply.started": "2025-04-25T17:21:17.707326Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Evaluate ---\n",
    "loss, acc = transformer_model.evaluate(X_test_char, y_test_char, verbose=0)\n",
    "print(f\"\\033[36mTransformer Accuracy (Char-level): {acc*100:.2f}%\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T17:23:42.566180Z",
     "iopub.status.busy": "2025-04-25T17:23:42.565918Z",
     "iopub.status.idle": "2025-04-25T17:24:00.319505Z",
     "shell.execute_reply": "2025-04-25T17:24:00.318837Z",
     "shell.execute_reply.started": "2025-04-25T17:23:42.566151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Predict class probabilities on test set\n",
    "y_pred_probs = transformer_model.predict(X_test_char)\n",
    "\n",
    "# Convert one-hot predictions and labels to class indices\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test_char, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Normalize confusion matrix by total values\n",
    "cf_matrix_normalized = cf_matrix.astype('float') / cf_matrix.sum()\n",
    "\n",
    "# Print label\n",
    "print('\\033[01m             Confusion Matrix \\033[0m')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cf_matrix_normalized, annot=True, fmt='.2%', cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Transformer Model - Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print('\\033[31m###################- End -###################\\033[0m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T17:24:44.631504Z",
     "iopub.status.busy": "2025-04-25T17:24:44.631032Z",
     "iopub.status.idle": "2025-04-25T17:24:44.795793Z",
     "shell.execute_reply": "2025-04-25T17:24:44.795040Z",
     "shell.execute_reply.started": "2025-04-25T17:24:44.631470Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print('\\n\\033[01mClassification Report:\\033[0m')\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T17:26:46.716512Z",
     "iopub.status.busy": "2025-04-25T17:26:46.716224Z",
     "iopub.status.idle": "2025-04-25T17:27:49.787110Z",
     "shell.execute_reply": "2025-04-25T17:27:49.786499Z",
     "shell.execute_reply.started": "2025-04-25T17:26:46.716480Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lstm_loss, lstm_acc = lstm_model.evaluate(X_test_char, y_test_char, verbose=0)\n",
    "cnn_lstm_loss, cnn_lstm_acc = cnn_lstm_model.evaluate(X_test_char, y_test_char, verbose=0)\n",
    "transformer_loss, transformer_acc = transformer_model.evaluate(X_test_char, y_test_char, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T17:27:59.072360Z",
     "iopub.status.busy": "2025-04-25T17:27:59.071752Z",
     "iopub.status.idle": "2025-04-25T17:27:59.386995Z",
     "shell.execute_reply": "2025-04-25T17:27:59.386180Z",
     "shell.execute_reply.started": "2025-04-25T17:27:59.072329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Automatically use the accuracy variables\n",
    "model_names = ['LSTM', 'CNN + LSTM', 'Transformer']\n",
    "accuracies = [lstm_acc * 100, cnn_lstm_acc * 100, transformer_acc * 100]  # convert to percentage\n",
    "\n",
    "# DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Accuracy': accuracies\n",
    "})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.set_style(\"whitegrid\")\n",
    "plot = sns.barplot(x='Model', y='Accuracy', data=results_df, palette='mako')\n",
    "plot.set_ylim(90, 100)\n",
    "\n",
    "# Annotate bars\n",
    "for bar in plot.patches:\n",
    "    plot.annotate(format(bar.get_height(), '.2f') + '%',\n",
    "                  (bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                  ha='center', va='bottom', size=12)\n",
    "\n",
    "plt.title(\"Model Accuracy Comparison\", fontsize=16)\n",
    "plt.xlabel(\"Model\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T17:38:41.192557Z",
     "iopub.status.busy": "2025-04-25T17:38:41.191967Z",
     "iopub.status.idle": "2025-04-25T17:38:41.200503Z",
     "shell.execute_reply": "2025-04-25T17:38:41.199834Z",
     "shell.execute_reply.started": "2025-04-25T17:38:41.192521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot_confusion_and_report(model, X_test, y_test, model_name=\"Model\", class_names=None):\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\n\\033[1mClassification Report - {model_name}:\\033[0m\")\n",
    "    if class_names:\n",
    "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    else:\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Custom colormap\n",
    "    colors = [\"#F5F5F5\", \"#FFD700\", \"#FFA500\", \"#FF4500\", \"#8B0000\"]\n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap=cmap,\n",
    "                xticklabels=class_names if class_names else None,\n",
    "                yticklabels=class_names if class_names else None)\n",
    "    plt.title(f'Normalized Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T17:38:56.907252Z",
     "iopub.status.busy": "2025-04-25T17:38:56.906775Z",
     "iopub.status.idle": "2025-04-25T17:39:55.116415Z",
     "shell.execute_reply": "2025-04-25T17:39:55.115567Z",
     "shell.execute_reply.started": "2025-04-25T17:38:56.907220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_names = ['benign','phishing' , 'defacement', 'malware']\n",
    "\n",
    "plot_confusion_and_report(lstm_model, X_test_char, y_test_char, model_name=\"LSTM\", class_names=class_names)\n",
    "plot_confusion_and_report(cnn_lstm_model, X_test_char, y_test_char, model_name=\"CNN + LSTM\", class_names=class_names)\n",
    "plot_confusion_and_report(transformer_model, X_test_char, y_test_char, model_name=\"Transformer\", class_names=class_names)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1486586,
     "sourceId": 2456026,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30152,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
